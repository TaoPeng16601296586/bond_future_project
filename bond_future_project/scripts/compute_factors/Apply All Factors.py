# apply_all_factors.py
# æ‰¹é‡è®¡ç®—å›½å€ºæœŸè´§çš„ TA-Lib + CICC åŠ¨é‡å› å­ + CICC æ³¢åŠ¨ç‡å› å­ï¼Œæ ‡å‡†åŒ–å¹¶ä¿å­˜åˆå¹¶è¾“å‡ºç»“æœ

import os
import pandas as pd
from cicc_momentum_factors import CICC_MomentumFactors
from cicc_volatility_factors import CICCVolatilityFactors
from ta_lib_factors import TALibFactors
from sklearn.preprocessing import StandardScaler

# === è·¯å¾„è®¾ç½® ===
DATA_DIR = r"C:/Users/l/OneDrive/æ¡Œé¢/æµ™å•†å›ºæ”¶/bond_future_project/data/raw data"
OUTPUT_DIR = r"C:/Users/l/OneDrive/æ¡Œé¢/æµ™å•†å›ºæ”¶/bond_future_project/data/factors/merged"
ALL_OUTPUT_PATH = os.path.join(OUTPUT_DIR, "å…¨å“ç§_åˆå¹¶å› å­æ±‡æ€».csv")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# === æ‰«ææ‰€æœ‰ä¸»è¿åˆçº¦æ–‡ä»¶ ===
files = [f for f in os.listdir(DATA_DIR) if "å›½å€ºæœŸè´§" in f and f.endswith(".csv")]

# å…¨éƒ¨åˆçº¦ç»“æœæ±‡æ€»å®¹å™¨
all_results = []

for file in files:
    print(f"\nğŸ“‚ æ­£åœ¨å¤„ç†ï¼š{file}")
    file_path = os.path.join(DATA_DIR, file)
    df = pd.read_csv(file_path, parse_dates=["date"])

    # === åˆå§‹åŒ–å¹¶è®¡ç®— TA-Lib å› å­ ===
    df_talib = TALibFactors(df).add_all()

    # === è®¡ç®— CICC åŠ¨é‡å› å­ ===
    df_mmt = CICC_MomentumFactors(df).apply_all_momentum_factors()

    # === è®¡ç®— CICC æ³¢åŠ¨ç‡å› å­ ===
    df_vol = CICCVolatilityFactors(df).add_all()

    # === åˆå¹¶å› å­è¡¨ï¼ˆæŒ‰ date åˆå¹¶ï¼‰ ===
    df_merged = df_talib.merge(df_mmt, on="date", how="left")
    df_merged = df_merged.merge(df_vol, on="date", how="left")

    # === æ·»åŠ  symbol å­—æ®µ ===
    symbol = file.split("_")[0]
    if "symbol" not in df_merged.columns:
        df_merged.insert(0, "symbol", symbol)
    else:
        df_merged["symbol"] = symbol

    # === é€‰æ‹©éœ€æ ‡å‡†åŒ–çš„æ•°å€¼åˆ—ï¼ˆæ’é™¤éæ•°å€¼å­—æ®µï¼‰ ===
    numeric_cols = df_merged.select_dtypes(include=["float64", "int64"]).columns.drop(["volume"], errors="ignore")
    standard_cols = [col for col in numeric_cols if col not in ["open", "high", "low", "close"]]

    # === ï¼ˆå¯é€‰ï¼‰æ ‡å‡†åŒ–å¤„ç†ï¼ˆZ-scoreï¼‰ ===ï¼ˆå½“å‰å·²è·³è¿‡ï¼Œä¿ç•™åŸå§‹å› å­å€¼ï¼‰
# scaler = StandardScaler()
# df_scaled = df_merged.copy()
# df_scaled[standard_cols] = scaler.fit_transform(df_scaled[standard_cols])

# å½“å‰ç›´æ¥ä½¿ç”¨åŸå§‹å› å­ç»“æœ
    df_scaled = df_merged.copy()

    output_file = file.replace("_å›½å€ºæœŸè´§.csv", "_åˆå¹¶å› å­.csv")
    output_path = os.path.join(OUTPUT_DIR, output_file)
    df_scaled.to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"âœ… åˆå¹¶å› å­ä¿å­˜è‡³ï¼š{output_path}")

    all_results.append(df_scaled)

# === åˆå¹¶æ‰€æœ‰å“ç§ä¸ºä¸€ä¸ªæ€»è¡¨ ===
if all_results:
    df_all = pd.concat(all_results, ignore_index=True)
    df_all.to_csv(ALL_OUTPUT_PATH, index=False, encoding="utf-8-sig")
    print(f"\nâœ… å…¨å“ç§åˆå¹¶å› å­å·²ä¿å­˜è‡³ï¼š{ALL_OUTPUT_PATH}")
